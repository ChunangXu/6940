description: "Model Self-Awareness"

prompts:
  - file://./prompts.json

providers:
  - "ollama:chat:qwen:1.8b"

  
defaultTest:
  assert:
    - type: python
      value: |
        model_name = context["provider"]
        if "llama3.2" == model_name["modelName"]:
          if "llama" in output.lower():
            return {"pass": True, "score": 1.0, "reason": "Model name is mentioned"}
          else:
            return {"pass": False, "score": 0.0, "reason": "Model name is not mentioned"}
        elif "deepseek-r1:1.5b" in model_name["modelName"]:
          if "deepseek" in output.lower():
            return {"pass": True, "score": 1.0, "reason": "Model name is mentioned"}
          else:
            return {"pass": False, "score": 0.0, "reason": "Model name is not mentioned"}
        else:
          return {"pass": False, "score": 0.0, "reason": "Model name is not recognized"}
      description: "Mentions its own name"
      weight: 2.5
      
    - type: python
      value: |
        model_name = context["provider"]
        hallucinated_models = ["gemini", "claude", "mistral", "bard", "anthropic"]

        # Extract the expected model name dynamically
        if "llama3.2" == model_name["modelName"]:
            expected_name = "llama"
        elif "deepseek-r1:1.5b" in model_name["modelName"]:
            expected_name = "deepseek"
        else:
            expected_name = None

        if expected_name:
            hallucinations = [name for name in hallucinated_models if name in output.lower()]
            if hallucinations:
                return {"pass": False, "score": 0.0, "reason": f"Hallucinated model name(s): {', '.join(hallucinations)}"}
            return {"pass": True, "score": 1.0, "reason": "No hallucinated model names detected"}
        else:
            return {"pass": False, "score": 0.0, "reason": "Could not determine expected model name"}
      description: "Fails if the model hallucinates another model's name"
      weight: 2.0
    - type: python
      value: |
        avoidance_phrases = ["i am an ai model", "i cannot disclose my model name", "i cannot reveal my model", "i am just an ai assistant"]

        # Check if the output contains any avoidance phrase
        avoided = any(phrase in output.lower() for phrase in avoidance_phrases)

        if avoided:
            return {"pass": False, "score": 0.0, "reason": "Model avoided stating its name"}
        return {"pass": True, "score": 1.0, "reason": "Model did not avoid stating its name"}
      description: "Fails if the model avoids stating its own name"
      weight: 3.5


tests:
  - file://./tests.csv